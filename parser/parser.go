// Package parser is generated by gogll. Do not edit.
package parser

import (
	"bytes"
	"fmt"
	"sort"
	"strings"

	"github.com/goccmack/3nf/lexer"
	"github.com/goccmack/3nf/parser/bsr"
	"github.com/goccmack/3nf/parser/slot"
	"github.com/goccmack/3nf/parser/symbols"
	"github.com/goccmack/3nf/token"
)

type parser struct {
	cI int

	R *descriptors
	U *descriptors

	popped   map[poppedNode]bool
	crf      map[clusterNode][]*crfNode
	crfNodes map[crfNode]*crfNode

	lex         *lexer.Lexer
	parseErrors []*Error

	bsrSet *bsr.Set
}

func newParser(l *lexer.Lexer) *parser {
	return &parser{
		cI:     0,
		lex:    l,
		R:      &descriptors{},
		U:      &descriptors{},
		popped: make(map[poppedNode]bool),
		crf: map[clusterNode][]*crfNode{
			{symbols.NT_Schema, 0}: {},
		},
		crfNodes:    map[crfNode]*crfNode{},
		bsrSet:      bsr.New(symbols.NT_Schema, l),
		parseErrors: nil,
	}
}

// Parse returns the BSR set containing the parse forest.
// If the parse was successfull []*Error is nil
func Parse(l *lexer.Lexer) (*bsr.Set, []*Error) {
	return newParser(l).parse()
}

func (p *parser) parse() (*bsr.Set, []*Error) {
	var L slot.Label
	m, cU := len(p.lex.Tokens)-1, 0
	p.ntAdd(symbols.NT_Schema, 0)
	// p.DumpDescriptors()
	for !p.R.empty() {
		L, cU, p.cI = p.R.remove()

		// fmt.Println()
		// fmt.Printf("L:%s, cI:%d, I[p.cI]:%s, cU:%d\n", L, p.cI, p.lex.Tokens[p.cI], cU)
		// p.DumpDescriptors()

		switch L {
		case slot.AttributeDeclaration0R0: // AttributeDeclaration : ∙AttributeName TypeName PrimaryKey

			p.call(slot.AttributeDeclaration0R1, cU, p.cI)
		case slot.AttributeDeclaration0R1: // AttributeDeclaration : AttributeName ∙TypeName PrimaryKey

			if !p.testSelect(slot.AttributeDeclaration0R1) {
				p.parseError(slot.AttributeDeclaration0R1, p.cI, first[slot.AttributeDeclaration0R1])
				break
			}

			p.call(slot.AttributeDeclaration0R2, cU, p.cI)
		case slot.AttributeDeclaration0R2: // AttributeDeclaration : AttributeName TypeName ∙PrimaryKey

			if !p.testSelect(slot.AttributeDeclaration0R2) {
				p.parseError(slot.AttributeDeclaration0R2, p.cI, first[slot.AttributeDeclaration0R2])
				break
			}

			p.call(slot.AttributeDeclaration0R3, cU, p.cI)
		case slot.AttributeDeclaration0R3: // AttributeDeclaration : AttributeName TypeName PrimaryKey ∙

			if p.follow(symbols.NT_AttributeDeclaration) {
				p.rtn(symbols.NT_AttributeDeclaration, cU, p.cI)
			} else {
				p.parseError(slot.AttributeDeclaration0R0, p.cI, followSets[symbols.NT_AttributeDeclaration])
			}
		case slot.AttributeDeclaration1R0: // AttributeDeclaration : ∙AttributeName TypeName Constraints

			p.call(slot.AttributeDeclaration1R1, cU, p.cI)
		case slot.AttributeDeclaration1R1: // AttributeDeclaration : AttributeName ∙TypeName Constraints

			if !p.testSelect(slot.AttributeDeclaration1R1) {
				p.parseError(slot.AttributeDeclaration1R1, p.cI, first[slot.AttributeDeclaration1R1])
				break
			}

			p.call(slot.AttributeDeclaration1R2, cU, p.cI)
		case slot.AttributeDeclaration1R2: // AttributeDeclaration : AttributeName TypeName ∙Constraints

			if !p.testSelect(slot.AttributeDeclaration1R2) {
				p.parseError(slot.AttributeDeclaration1R2, p.cI, first[slot.AttributeDeclaration1R2])
				break
			}

			p.call(slot.AttributeDeclaration1R3, cU, p.cI)
		case slot.AttributeDeclaration1R3: // AttributeDeclaration : AttributeName TypeName Constraints ∙

			if p.follow(symbols.NT_AttributeDeclaration) {
				p.rtn(symbols.NT_AttributeDeclaration, cU, p.cI)
			} else {
				p.parseError(slot.AttributeDeclaration1R0, p.cI, followSets[symbols.NT_AttributeDeclaration])
			}
		case slot.AttributeDeclaration2R0: // AttributeDeclaration : ∙AttributeName TypeName [] Constraints

			p.call(slot.AttributeDeclaration2R1, cU, p.cI)
		case slot.AttributeDeclaration2R1: // AttributeDeclaration : AttributeName ∙TypeName [] Constraints

			if !p.testSelect(slot.AttributeDeclaration2R1) {
				p.parseError(slot.AttributeDeclaration2R1, p.cI, first[slot.AttributeDeclaration2R1])
				break
			}

			p.call(slot.AttributeDeclaration2R2, cU, p.cI)
		case slot.AttributeDeclaration2R2: // AttributeDeclaration : AttributeName TypeName ∙[] Constraints

			if !p.testSelect(slot.AttributeDeclaration2R2) {
				p.parseError(slot.AttributeDeclaration2R2, p.cI, first[slot.AttributeDeclaration2R2])
				break
			}

			p.bsrSet.Add(slot.AttributeDeclaration2R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.AttributeDeclaration2R3) {
				p.parseError(slot.AttributeDeclaration2R3, p.cI, first[slot.AttributeDeclaration2R3])
				break
			}

			p.call(slot.AttributeDeclaration2R4, cU, p.cI)
		case slot.AttributeDeclaration2R4: // AttributeDeclaration : AttributeName TypeName [] Constraints ∙

			if p.follow(symbols.NT_AttributeDeclaration) {
				p.rtn(symbols.NT_AttributeDeclaration, cU, p.cI)
			} else {
				p.parseError(slot.AttributeDeclaration2R0, p.cI, followSets[symbols.NT_AttributeDeclaration])
			}
		case slot.AttributeDeclarations0R0: // AttributeDeclarations : ∙AttributeDeclaration

			p.call(slot.AttributeDeclarations0R1, cU, p.cI)
		case slot.AttributeDeclarations0R1: // AttributeDeclarations : AttributeDeclaration ∙

			if p.follow(symbols.NT_AttributeDeclarations) {
				p.rtn(symbols.NT_AttributeDeclarations, cU, p.cI)
			} else {
				p.parseError(slot.AttributeDeclarations0R0, p.cI, followSets[symbols.NT_AttributeDeclarations])
			}
		case slot.AttributeDeclarations1R0: // AttributeDeclarations : ∙AttributeDeclaration AttributeDeclarations

			p.call(slot.AttributeDeclarations1R1, cU, p.cI)
		case slot.AttributeDeclarations1R1: // AttributeDeclarations : AttributeDeclaration ∙AttributeDeclarations

			if !p.testSelect(slot.AttributeDeclarations1R1) {
				p.parseError(slot.AttributeDeclarations1R1, p.cI, first[slot.AttributeDeclarations1R1])
				break
			}

			p.call(slot.AttributeDeclarations1R2, cU, p.cI)
		case slot.AttributeDeclarations1R2: // AttributeDeclarations : AttributeDeclaration AttributeDeclarations ∙

			if p.follow(symbols.NT_AttributeDeclarations) {
				p.rtn(symbols.NT_AttributeDeclarations, cU, p.cI)
			} else {
				p.parseError(slot.AttributeDeclarations1R0, p.cI, followSets[symbols.NT_AttributeDeclarations])
			}
		case slot.AttributeName0R0: // AttributeName : ∙Name

			p.call(slot.AttributeName0R1, cU, p.cI)
		case slot.AttributeName0R1: // AttributeName : Name ∙

			if p.follow(symbols.NT_AttributeName) {
				p.rtn(symbols.NT_AttributeName, cU, p.cI)
			} else {
				p.parseError(slot.AttributeName0R0, p.cI, followSets[symbols.NT_AttributeName])
			}
		case slot.Constraint0R0: // Constraint : ∙ForeignKey

			p.call(slot.Constraint0R1, cU, p.cI)
		case slot.Constraint0R1: // Constraint : ForeignKey ∙

			if p.follow(symbols.NT_Constraint) {
				p.rtn(symbols.NT_Constraint, cU, p.cI)
			} else {
				p.parseError(slot.Constraint0R0, p.cI, followSets[symbols.NT_Constraint])
			}
		case slot.Constraint1R0: // Constraint : ∙Nullable

			p.call(slot.Constraint1R1, cU, p.cI)
		case slot.Constraint1R1: // Constraint : Nullable ∙

			if p.follow(symbols.NT_Constraint) {
				p.rtn(symbols.NT_Constraint, cU, p.cI)
			} else {
				p.parseError(slot.Constraint1R0, p.cI, followSets[symbols.NT_Constraint])
			}
		case slot.Constraint2R0: // Constraint : ∙Unique

			p.call(slot.Constraint2R1, cU, p.cI)
		case slot.Constraint2R1: // Constraint : Unique ∙

			if p.follow(symbols.NT_Constraint) {
				p.rtn(symbols.NT_Constraint, cU, p.cI)
			} else {
				p.parseError(slot.Constraint2R0, p.cI, followSets[symbols.NT_Constraint])
			}
		case slot.Constraints0R0: // Constraints : ∙Constraint Constraints

			p.call(slot.Constraints0R1, cU, p.cI)
		case slot.Constraints0R1: // Constraints : Constraint ∙Constraints

			if !p.testSelect(slot.Constraints0R1) {
				p.parseError(slot.Constraints0R1, p.cI, first[slot.Constraints0R1])
				break
			}

			p.call(slot.Constraints0R2, cU, p.cI)
		case slot.Constraints0R2: // Constraints : Constraint Constraints ∙

			if p.follow(symbols.NT_Constraints) {
				p.rtn(symbols.NT_Constraints, cU, p.cI)
			} else {
				p.parseError(slot.Constraints0R0, p.cI, followSets[symbols.NT_Constraints])
			}
		case slot.Constraints1R0: // Constraints : ∙
			p.bsrSet.AddEmpty(slot.Constraints1R0, p.cI)

			if p.follow(symbols.NT_Constraints) {
				p.rtn(symbols.NT_Constraints, cU, p.cI)
			} else {
				p.parseError(slot.Constraints1R0, p.cI, followSets[symbols.NT_Constraints])
			}
		case slot.Description0R0: // Description : ∙string

			p.bsrSet.Add(slot.Description0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Description) {
				p.rtn(symbols.NT_Description, cU, p.cI)
			} else {
				p.parseError(slot.Description0R0, p.cI, followSets[symbols.NT_Description])
			}
		case slot.Description1R0: // Description : ∙
			p.bsrSet.AddEmpty(slot.Description1R0, p.cI)

			if p.follow(symbols.NT_Description) {
				p.rtn(symbols.NT_Description, cU, p.cI)
			} else {
				p.parseError(slot.Description1R0, p.cI, followSets[symbols.NT_Description])
			}
		case slot.ERM0R0: // ERM : ∙EntityOrEnum ERM

			p.call(slot.ERM0R1, cU, p.cI)
		case slot.ERM0R1: // ERM : EntityOrEnum ∙ERM

			if !p.testSelect(slot.ERM0R1) {
				p.parseError(slot.ERM0R1, p.cI, first[slot.ERM0R1])
				break
			}

			p.call(slot.ERM0R2, cU, p.cI)
		case slot.ERM0R2: // ERM : EntityOrEnum ERM ∙

			if p.follow(symbols.NT_ERM) {
				p.rtn(symbols.NT_ERM, cU, p.cI)
			} else {
				p.parseError(slot.ERM0R0, p.cI, followSets[symbols.NT_ERM])
			}
		case slot.ERM1R0: // ERM : ∙EntityOrEnum

			p.call(slot.ERM1R1, cU, p.cI)
		case slot.ERM1R1: // ERM : EntityOrEnum ∙

			if p.follow(symbols.NT_ERM) {
				p.rtn(symbols.NT_ERM, cU, p.cI)
			} else {
				p.parseError(slot.ERM1R0, p.cI, followSets[symbols.NT_ERM])
			}
		case slot.Entity0R0: // Entity : ∙EntityName { AttributeDeclarations }

			p.call(slot.Entity0R1, cU, p.cI)
		case slot.Entity0R1: // Entity : EntityName ∙{ AttributeDeclarations }

			if !p.testSelect(slot.Entity0R1) {
				p.parseError(slot.Entity0R1, p.cI, first[slot.Entity0R1])
				break
			}

			p.bsrSet.Add(slot.Entity0R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Entity0R2) {
				p.parseError(slot.Entity0R2, p.cI, first[slot.Entity0R2])
				break
			}

			p.call(slot.Entity0R3, cU, p.cI)
		case slot.Entity0R3: // Entity : EntityName { AttributeDeclarations ∙}

			if !p.testSelect(slot.Entity0R3) {
				p.parseError(slot.Entity0R3, p.cI, first[slot.Entity0R3])
				break
			}

			p.bsrSet.Add(slot.Entity0R4, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Entity) {
				p.rtn(symbols.NT_Entity, cU, p.cI)
			} else {
				p.parseError(slot.Entity0R0, p.cI, followSets[symbols.NT_Entity])
			}
		case slot.Entity1R0: // Entity : ∙EntityName { }

			p.call(slot.Entity1R1, cU, p.cI)
		case slot.Entity1R1: // Entity : EntityName ∙{ }

			if !p.testSelect(slot.Entity1R1) {
				p.parseError(slot.Entity1R1, p.cI, first[slot.Entity1R1])
				break
			}

			p.bsrSet.Add(slot.Entity1R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Entity1R2) {
				p.parseError(slot.Entity1R2, p.cI, first[slot.Entity1R2])
				break
			}

			p.bsrSet.Add(slot.Entity1R3, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Entity) {
				p.rtn(symbols.NT_Entity, cU, p.cI)
			} else {
				p.parseError(slot.Entity1R0, p.cI, followSets[symbols.NT_Entity])
			}
		case slot.EntityName0R0: // EntityName : ∙Name

			p.call(slot.EntityName0R1, cU, p.cI)
		case slot.EntityName0R1: // EntityName : Name ∙

			if p.follow(symbols.NT_EntityName) {
				p.rtn(symbols.NT_EntityName, cU, p.cI)
			} else {
				p.parseError(slot.EntityName0R0, p.cI, followSets[symbols.NT_EntityName])
			}
		case slot.EntityOrEnum0R0: // EntityOrEnum : ∙Entity

			p.call(slot.EntityOrEnum0R1, cU, p.cI)
		case slot.EntityOrEnum0R1: // EntityOrEnum : Entity ∙

			if p.follow(symbols.NT_EntityOrEnum) {
				p.rtn(symbols.NT_EntityOrEnum, cU, p.cI)
			} else {
				p.parseError(slot.EntityOrEnum0R0, p.cI, followSets[symbols.NT_EntityOrEnum])
			}
		case slot.EntityOrEnum1R0: // EntityOrEnum : ∙Enum

			p.call(slot.EntityOrEnum1R1, cU, p.cI)
		case slot.EntityOrEnum1R1: // EntityOrEnum : Enum ∙

			if p.follow(symbols.NT_EntityOrEnum) {
				p.rtn(symbols.NT_EntityOrEnum, cU, p.cI)
			} else {
				p.parseError(slot.EntityOrEnum1R0, p.cI, followSets[symbols.NT_EntityOrEnum])
			}
		case slot.Enum0R0: // Enum : ∙enum name { EnumItems }

			p.bsrSet.Add(slot.Enum0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Enum0R1) {
				p.parseError(slot.Enum0R1, p.cI, first[slot.Enum0R1])
				break
			}

			p.bsrSet.Add(slot.Enum0R2, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Enum0R2) {
				p.parseError(slot.Enum0R2, p.cI, first[slot.Enum0R2])
				break
			}

			p.bsrSet.Add(slot.Enum0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Enum0R3) {
				p.parseError(slot.Enum0R3, p.cI, first[slot.Enum0R3])
				break
			}

			p.call(slot.Enum0R4, cU, p.cI)
		case slot.Enum0R4: // Enum : enum name { EnumItems ∙}

			if !p.testSelect(slot.Enum0R4) {
				p.parseError(slot.Enum0R4, p.cI, first[slot.Enum0R4])
				break
			}

			p.bsrSet.Add(slot.Enum0R5, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Enum) {
				p.rtn(symbols.NT_Enum, cU, p.cI)
			} else {
				p.parseError(slot.Enum0R0, p.cI, followSets[symbols.NT_Enum])
			}
		case slot.EnumItem0R0: // EnumItem : ∙EnumItemName Description = SequenceNumber ;

			p.call(slot.EnumItem0R1, cU, p.cI)
		case slot.EnumItem0R1: // EnumItem : EnumItemName ∙Description = SequenceNumber ;

			if !p.testSelect(slot.EnumItem0R1) {
				p.parseError(slot.EnumItem0R1, p.cI, first[slot.EnumItem0R1])
				break
			}

			p.call(slot.EnumItem0R2, cU, p.cI)
		case slot.EnumItem0R2: // EnumItem : EnumItemName Description ∙= SequenceNumber ;

			if !p.testSelect(slot.EnumItem0R2) {
				p.parseError(slot.EnumItem0R2, p.cI, first[slot.EnumItem0R2])
				break
			}

			p.bsrSet.Add(slot.EnumItem0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.EnumItem0R3) {
				p.parseError(slot.EnumItem0R3, p.cI, first[slot.EnumItem0R3])
				break
			}

			p.call(slot.EnumItem0R4, cU, p.cI)
		case slot.EnumItem0R4: // EnumItem : EnumItemName Description = SequenceNumber ∙;

			if !p.testSelect(slot.EnumItem0R4) {
				p.parseError(slot.EnumItem0R4, p.cI, first[slot.EnumItem0R4])
				break
			}

			p.bsrSet.Add(slot.EnumItem0R5, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_EnumItem) {
				p.rtn(symbols.NT_EnumItem, cU, p.cI)
			} else {
				p.parseError(slot.EnumItem0R0, p.cI, followSets[symbols.NT_EnumItem])
			}
		case slot.EnumItemName0R0: // EnumItemName : ∙string

			p.bsrSet.Add(slot.EnumItemName0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_EnumItemName) {
				p.rtn(symbols.NT_EnumItemName, cU, p.cI)
			} else {
				p.parseError(slot.EnumItemName0R0, p.cI, followSets[symbols.NT_EnumItemName])
			}
		case slot.EnumItems0R0: // EnumItems : ∙EnumItem EnumItems

			p.call(slot.EnumItems0R1, cU, p.cI)
		case slot.EnumItems0R1: // EnumItems : EnumItem ∙EnumItems

			if !p.testSelect(slot.EnumItems0R1) {
				p.parseError(slot.EnumItems0R1, p.cI, first[slot.EnumItems0R1])
				break
			}

			p.call(slot.EnumItems0R2, cU, p.cI)
		case slot.EnumItems0R2: // EnumItems : EnumItem EnumItems ∙

			if p.follow(symbols.NT_EnumItems) {
				p.rtn(symbols.NT_EnumItems, cU, p.cI)
			} else {
				p.parseError(slot.EnumItems0R0, p.cI, followSets[symbols.NT_EnumItems])
			}
		case slot.EnumItems1R0: // EnumItems : ∙EnumItem

			p.call(slot.EnumItems1R1, cU, p.cI)
		case slot.EnumItems1R1: // EnumItems : EnumItem ∙

			if p.follow(symbols.NT_EnumItems) {
				p.rtn(symbols.NT_EnumItems, cU, p.cI)
			} else {
				p.parseError(slot.EnumItems1R0, p.cI, followSets[symbols.NT_EnumItems])
			}
		case slot.FieldName0R0: // FieldName : ∙Name

			p.call(slot.FieldName0R1, cU, p.cI)
		case slot.FieldName0R1: // FieldName : Name ∙

			if p.follow(symbols.NT_FieldName) {
				p.rtn(symbols.NT_FieldName, cU, p.cI)
			} else {
				p.parseError(slot.FieldName0R0, p.cI, followSets[symbols.NT_FieldName])
			}
		case slot.ForeignKey0R0: // ForeignKey : ∙FK EntityName . FieldName

			p.bsrSet.Add(slot.ForeignKey0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.ForeignKey0R1) {
				p.parseError(slot.ForeignKey0R1, p.cI, first[slot.ForeignKey0R1])
				break
			}

			p.call(slot.ForeignKey0R2, cU, p.cI)
		case slot.ForeignKey0R2: // ForeignKey : FK EntityName ∙. FieldName

			if !p.testSelect(slot.ForeignKey0R2) {
				p.parseError(slot.ForeignKey0R2, p.cI, first[slot.ForeignKey0R2])
				break
			}

			p.bsrSet.Add(slot.ForeignKey0R3, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.ForeignKey0R3) {
				p.parseError(slot.ForeignKey0R3, p.cI, first[slot.ForeignKey0R3])
				break
			}

			p.call(slot.ForeignKey0R4, cU, p.cI)
		case slot.ForeignKey0R4: // ForeignKey : FK EntityName . FieldName ∙

			if p.follow(symbols.NT_ForeignKey) {
				p.rtn(symbols.NT_ForeignKey, cU, p.cI)
			} else {
				p.parseError(slot.ForeignKey0R0, p.cI, followSets[symbols.NT_ForeignKey])
			}
		case slot.Name0R0: // Name : ∙name

			p.bsrSet.Add(slot.Name0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Name) {
				p.rtn(symbols.NT_Name, cU, p.cI)
			} else {
				p.parseError(slot.Name0R0, p.cI, followSets[symbols.NT_Name])
			}
		case slot.Nullable0R0: // Nullable : ∙null

			p.bsrSet.Add(slot.Nullable0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Nullable) {
				p.rtn(symbols.NT_Nullable, cU, p.cI)
			} else {
				p.parseError(slot.Nullable0R0, p.cI, followSets[symbols.NT_Nullable])
			}
		case slot.Nullable1R0: // Nullable : ∙not null

			p.bsrSet.Add(slot.Nullable1R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Nullable1R1) {
				p.parseError(slot.Nullable1R1, p.cI, first[slot.Nullable1R1])
				break
			}

			p.bsrSet.Add(slot.Nullable1R2, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Nullable) {
				p.rtn(symbols.NT_Nullable, cU, p.cI)
			} else {
				p.parseError(slot.Nullable1R0, p.cI, followSets[symbols.NT_Nullable])
			}
		case slot.PrimaryKey0R0: // PrimaryKey : ∙PK

			p.bsrSet.Add(slot.PrimaryKey0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_PrimaryKey) {
				p.rtn(symbols.NT_PrimaryKey, cU, p.cI)
			} else {
				p.parseError(slot.PrimaryKey0R0, p.cI, followSets[symbols.NT_PrimaryKey])
			}
		case slot.Schema0R0: // Schema : ∙schema SchemaName ERM

			p.bsrSet.Add(slot.Schema0R1, cU, p.cI, p.cI+1)
			p.cI++
			if !p.testSelect(slot.Schema0R1) {
				p.parseError(slot.Schema0R1, p.cI, first[slot.Schema0R1])
				break
			}

			p.call(slot.Schema0R2, cU, p.cI)
		case slot.Schema0R2: // Schema : schema SchemaName ∙ERM

			if !p.testSelect(slot.Schema0R2) {
				p.parseError(slot.Schema0R2, p.cI, first[slot.Schema0R2])
				break
			}

			p.call(slot.Schema0R3, cU, p.cI)
		case slot.Schema0R3: // Schema : schema SchemaName ERM ∙

			if p.follow(symbols.NT_Schema) {
				p.rtn(symbols.NT_Schema, cU, p.cI)
			} else {
				p.parseError(slot.Schema0R0, p.cI, followSets[symbols.NT_Schema])
			}
		case slot.SchemaName0R0: // SchemaName : ∙Name

			p.call(slot.SchemaName0R1, cU, p.cI)
		case slot.SchemaName0R1: // SchemaName : Name ∙

			if p.follow(symbols.NT_SchemaName) {
				p.rtn(symbols.NT_SchemaName, cU, p.cI)
			} else {
				p.parseError(slot.SchemaName0R0, p.cI, followSets[symbols.NT_SchemaName])
			}
		case slot.SequenceNumber0R0: // SequenceNumber : ∙posint

			p.bsrSet.Add(slot.SequenceNumber0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_SequenceNumber) {
				p.rtn(symbols.NT_SequenceNumber, cU, p.cI)
			} else {
				p.parseError(slot.SequenceNumber0R0, p.cI, followSets[symbols.NT_SequenceNumber])
			}
		case slot.TypeName0R0: // TypeName : ∙bin

			p.bsrSet.Add(slot.TypeName0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName0R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName1R0: // TypeName : ∙bool

			p.bsrSet.Add(slot.TypeName1R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName1R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName2R0: // TypeName : ∙date

			p.bsrSet.Add(slot.TypeName2R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName2R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName3R0: // TypeName : ∙decimal

			p.bsrSet.Add(slot.TypeName3R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName3R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName4R0: // TypeName : ∙int

			p.bsrSet.Add(slot.TypeName4R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName4R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName5R0: // TypeName : ∙serial

			p.bsrSet.Add(slot.TypeName5R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName5R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName6R0: // TypeName : ∙text

			p.bsrSet.Add(slot.TypeName6R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName6R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.TypeName7R0: // TypeName : ∙time

			p.bsrSet.Add(slot.TypeName7R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_TypeName) {
				p.rtn(symbols.NT_TypeName, cU, p.cI)
			} else {
				p.parseError(slot.TypeName7R0, p.cI, followSets[symbols.NT_TypeName])
			}
		case slot.Unique0R0: // Unique : ∙unique

			p.bsrSet.Add(slot.Unique0R1, cU, p.cI, p.cI+1)
			p.cI++
			if p.follow(symbols.NT_Unique) {
				p.rtn(symbols.NT_Unique, cU, p.cI)
			} else {
				p.parseError(slot.Unique0R0, p.cI, followSets[symbols.NT_Unique])
			}

		default:
			panic("This must not happen")
		}
	}
	if !p.bsrSet.Contain(symbols.NT_Schema, 0, m) {
		p.sortParseErrors()
		return nil, p.parseErrors
	}
	return p.bsrSet, nil
}

func (p *parser) ntAdd(nt symbols.NT, j int) {
	// fmt.Printf("p.ntAdd(%s, %d)\n", nt, j)
	failed := true
	expected := map[token.Type]string{}
	for _, l := range slot.GetAlternates(nt) {
		if p.testSelect(l) {
			p.dscAdd(l, j, j)
			failed = false
		} else {
			for k, v := range first[l] {
				expected[k] = v
			}
		}
	}
	if failed {
		for _, l := range slot.GetAlternates(nt) {
			p.parseError(l, j, expected)
		}
	}
}

/*** Call Return Forest ***/

type poppedNode struct {
	X    symbols.NT
	k, j int
}

type clusterNode struct {
	X symbols.NT
	k int
}

type crfNode struct {
	L slot.Label
	i int
}

/*
suppose that L is Y ::=αX ·β
if there is no CRF node labelled (L,i)

	create one let u be the CRF node labelled (L,i)

if there is no CRF node labelled (X, j) {

		create a CRF node v labelled (X, j)
		create an edge from v to u
		ntAdd(X, j)
	} else {

		let v be the CRF node labelled (X, j)
		if there is not an edge from v to u {
			create an edge from v to u
			for all ((X, j,h)∈P) {
				dscAdd(L, i, h);
				bsrAdd(L, i, j, h)
			}
		}
	}
*/
func (p *parser) call(L slot.Label, i, j int) {
	// fmt.Printf("p.call(%s,%d,%d)\n", L,i,j)
	u, exist := p.crfNodes[crfNode{L, i}]
	// fmt.Printf("  u exist=%t\n", exist)
	if !exist {
		u = &crfNode{L, i}
		p.crfNodes[*u] = u
	}
	X := L.Symbols()[L.Pos()-1].(symbols.NT)
	ndV := clusterNode{X, j}
	v, exist := p.crf[ndV]
	if !exist {
		// fmt.Println("  v !exist")
		p.crf[ndV] = []*crfNode{u}
		p.ntAdd(X, j)
	} else {
		// fmt.Println("  v exist")
		if !existEdge(v, u) {
			// fmt.Printf("  !existEdge(%v)\n", u)
			p.crf[ndV] = append(v, u)
			// fmt.Printf("|popped|=%d\n", len(popped))
			for pnd := range p.popped {
				if pnd.X == X && pnd.k == j {
					p.dscAdd(L, i, pnd.j)
					p.bsrSet.Add(L, i, j, pnd.j)
				}
			}
		}
	}
}

func existEdge(nds []*crfNode, nd *crfNode) bool {
	for _, nd1 := range nds {
		if nd1 == nd {
			return true
		}
	}
	return false
}

func (p *parser) rtn(X symbols.NT, k, j int) {
	// fmt.Printf("p.rtn(%s,%d,%d)\n", X,k,j)
	pn := poppedNode{X, k, j}
	if _, exist := p.popped[pn]; !exist {
		p.popped[pn] = true
		for _, nd := range p.crf[clusterNode{X, k}] {
			p.dscAdd(nd.L, nd.i, j)
			p.bsrSet.Add(nd.L, nd.i, k, j)
		}
	}
}

// func CRFString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("CRF: {")
// 	for cn, nds := range crf{
// 		for _, nd := range nds {
// 			fmt.Fprintf(buf, "%s->%s, ", cn, nd)
// 		}
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

func (cn clusterNode) String() string {
	return fmt.Sprintf("(%s,%d)", cn.X, cn.k)
}

func (n crfNode) String() string {
	return fmt.Sprintf("(%s,%d)", n.L.String(), n.i)
}

// func PoppedString() string {
// 	buf := new(bytes.Buffer)
// 	buf.WriteString("Popped: {")
// 	for p, _ := range popped {
// 		fmt.Fprintf(buf, "(%s,%d,%d) ", p.X, p.k, p.j)
// 	}
// 	buf.WriteString("}")
// 	return buf.String()
// }

/*** descriptors ***/

type descriptors struct {
	set []*descriptor
}

func (ds *descriptors) contain(d *descriptor) bool {
	for _, d1 := range ds.set {
		if d1 == d {
			return true
		}
	}
	return false
}

func (ds *descriptors) empty() bool {
	return len(ds.set) == 0
}

func (ds *descriptors) String() string {
	buf := new(bytes.Buffer)
	buf.WriteString("{")
	for i, d := range ds.set {
		if i > 0 {
			buf.WriteString("; ")
		}
		fmt.Fprintf(buf, "%s", d)
	}
	buf.WriteString("}")
	return buf.String()
}

type descriptor struct {
	L slot.Label
	k int
	i int
}

func (d *descriptor) String() string {
	return fmt.Sprintf("%s,%d,%d", d.L, d.k, d.i)
}

func (p *parser) dscAdd(L slot.Label, k, i int) {
	// fmt.Printf("p.dscAdd(%s,%d,%d)\n", L, k, i)
	d := &descriptor{L, k, i}
	if !p.U.contain(d) {
		p.R.set = append(p.R.set, d)
		p.U.set = append(p.U.set, d)
	}
}

func (ds *descriptors) remove() (L slot.Label, k, i int) {
	d := ds.set[len(ds.set)-1]
	ds.set = ds.set[:len(ds.set)-1]
	// fmt.Printf("remove: %s,%d,%d\n", d.L, d.k, d.i)
	return d.L, d.k, d.i
}

func (p *parser) DumpDescriptors() {
	p.DumpR()
	p.DumpU()
}

func (p *parser) DumpR() {
	fmt.Println("R:")
	for _, d := range p.R.set {
		fmt.Printf(" %s\n", d)
	}
}

func (p *parser) DumpU() {
	fmt.Println("U:")
	for _, d := range p.U.set {
		fmt.Printf(" %s\n", d)
	}
}

/*** TestSelect ***/

func (p *parser) follow(nt symbols.NT) bool {
	_, exist := followSets[nt][p.lex.Tokens[p.cI].Type()]
	return exist
}

func (p *parser) testSelect(l slot.Label) bool {
	_, exist := first[l][p.lex.Tokens[p.cI].Type()]
	// fmt.Printf("testSelect(%s) = %t\n", l, exist)
	return exist
}

var first = []map[token.Type]string{
	// AttributeDeclaration : ∙AttributeName TypeName PrimaryKey
	{
		token.T_13: "name",
	},
	// AttributeDeclaration : AttributeName ∙TypeName PrimaryKey
	{
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_11: "int",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
	},
	// AttributeDeclaration : AttributeName TypeName ∙PrimaryKey
	{
		token.T_4: "PK",
	},
	// AttributeDeclaration : AttributeName TypeName PrimaryKey ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclaration : ∙AttributeName TypeName Constraints
	{
		token.T_13: "name",
	},
	// AttributeDeclaration : AttributeName ∙TypeName Constraints
	{
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_11: "int",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
	},
	// AttributeDeclaration : AttributeName TypeName ∙Constraints
	{
		token.T_3:  "FK",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclaration : AttributeName TypeName Constraints ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclaration : ∙AttributeName TypeName [] Constraints
	{
		token.T_13: "name",
	},
	// AttributeDeclaration : AttributeName ∙TypeName [] Constraints
	{
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_11: "int",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
	},
	// AttributeDeclaration : AttributeName TypeName ∙[] Constraints
	{
		token.T_5: "[]",
	},
	// AttributeDeclaration : AttributeName TypeName [] ∙Constraints
	{
		token.T_3:  "FK",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclaration : AttributeName TypeName [] Constraints ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclarations : ∙AttributeDeclaration
	{
		token.T_13: "name",
	},
	// AttributeDeclarations : AttributeDeclaration ∙
	{
		token.T_24: "}",
	},
	// AttributeDeclarations : ∙AttributeDeclaration AttributeDeclarations
	{
		token.T_13: "name",
	},
	// AttributeDeclarations : AttributeDeclaration ∙AttributeDeclarations
	{
		token.T_13: "name",
	},
	// AttributeDeclarations : AttributeDeclaration AttributeDeclarations ∙
	{
		token.T_24: "}",
	},
	// AttributeName : ∙Name
	{
		token.T_13: "name",
	},
	// AttributeName : Name ∙
	{
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_11: "int",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
	},
	// Constraint : ∙ForeignKey
	{
		token.T_3: "FK",
	},
	// Constraint : ForeignKey ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Constraint : ∙Nullable
	{
		token.T_14: "not",
		token.T_15: "null",
	},
	// Constraint : Nullable ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Constraint : ∙Unique
	{
		token.T_22: "unique",
	},
	// Constraint : Unique ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Constraints : ∙Constraint Constraints
	{
		token.T_3:  "FK",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
	},
	// Constraints : Constraint ∙Constraints
	{
		token.T_3:  "FK",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_13: "name",
		token.T_24: "}",
	},
	// Constraints : Constraint Constraints ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// Constraints : ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// Description : ∙string
	{
		token.T_19: "string",
	},
	// Description : string ∙
	{
		token.T_2: "=",
	},
	// Description : ∙
	{
		token.T_2: "=",
	},
	// ERM : ∙EntityOrEnum ERM
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// ERM : EntityOrEnum ∙ERM
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// ERM : EntityOrEnum ERM ∙
	{
		token.EOF: "$",
	},
	// ERM : ∙EntityOrEnum
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// ERM : EntityOrEnum ∙
	{
		token.EOF: "$",
	},
	// Entity : ∙EntityName { AttributeDeclarations }
	{
		token.T_13: "name",
	},
	// Entity : EntityName ∙{ AttributeDeclarations }
	{
		token.T_23: "{",
	},
	// Entity : EntityName { ∙AttributeDeclarations }
	{
		token.T_13: "name",
	},
	// Entity : EntityName { AttributeDeclarations ∙}
	{
		token.T_24: "}",
	},
	// Entity : EntityName { AttributeDeclarations } ∙
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// Entity : ∙EntityName { }
	{
		token.T_13: "name",
	},
	// Entity : EntityName ∙{ }
	{
		token.T_23: "{",
	},
	// Entity : EntityName { ∙}
	{
		token.T_24: "}",
	},
	// Entity : EntityName { } ∙
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// EntityName : ∙Name
	{
		token.T_13: "name",
	},
	// EntityName : Name ∙
	{
		token.T_0:  ".",
		token.T_23: "{",
	},
	// EntityOrEnum : ∙Entity
	{
		token.T_13: "name",
	},
	// EntityOrEnum : Entity ∙
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// EntityOrEnum : ∙Enum
	{
		token.T_10: "enum",
	},
	// EntityOrEnum : Enum ∙
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// Enum : ∙enum name { EnumItems }
	{
		token.T_10: "enum",
	},
	// Enum : enum ∙name { EnumItems }
	{
		token.T_13: "name",
	},
	// Enum : enum name ∙{ EnumItems }
	{
		token.T_23: "{",
	},
	// Enum : enum name { ∙EnumItems }
	{
		token.T_19: "string",
	},
	// Enum : enum name { EnumItems ∙}
	{
		token.T_24: "}",
	},
	// Enum : enum name { EnumItems } ∙
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// EnumItem : ∙EnumItemName Description = SequenceNumber ;
	{
		token.T_19: "string",
	},
	// EnumItem : EnumItemName ∙Description = SequenceNumber ;
	{
		token.T_2:  "=",
		token.T_19: "string",
	},
	// EnumItem : EnumItemName Description ∙= SequenceNumber ;
	{
		token.T_2: "=",
	},
	// EnumItem : EnumItemName Description = ∙SequenceNumber ;
	{
		token.T_16: "posint",
	},
	// EnumItem : EnumItemName Description = SequenceNumber ∙;
	{
		token.T_1: ";",
	},
	// EnumItem : EnumItemName Description = SequenceNumber ; ∙
	{
		token.T_19: "string",
		token.T_24: "}",
	},
	// EnumItemName : ∙string
	{
		token.T_19: "string",
	},
	// EnumItemName : string ∙
	{
		token.T_2:  "=",
		token.T_19: "string",
	},
	// EnumItems : ∙EnumItem EnumItems
	{
		token.T_19: "string",
	},
	// EnumItems : EnumItem ∙EnumItems
	{
		token.T_19: "string",
	},
	// EnumItems : EnumItem EnumItems ∙
	{
		token.T_24: "}",
	},
	// EnumItems : ∙EnumItem
	{
		token.T_19: "string",
	},
	// EnumItems : EnumItem ∙
	{
		token.T_24: "}",
	},
	// FieldName : ∙Name
	{
		token.T_13: "name",
	},
	// FieldName : Name ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// ForeignKey : ∙FK EntityName . FieldName
	{
		token.T_3: "FK",
	},
	// ForeignKey : FK ∙EntityName . FieldName
	{
		token.T_13: "name",
	},
	// ForeignKey : FK EntityName ∙. FieldName
	{
		token.T_0: ".",
	},
	// ForeignKey : FK EntityName . ∙FieldName
	{
		token.T_13: "name",
	},
	// ForeignKey : FK EntityName . FieldName ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Name : ∙name
	{
		token.T_13: "name",
	},
	// Name : name ∙
	{
		token.T_0:  ".",
		token.T_3:  "FK",
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_10: "enum",
		token.T_11: "int",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
		token.T_22: "unique",
		token.T_23: "{",
		token.T_24: "}",
	},
	// Nullable : ∙null
	{
		token.T_15: "null",
	},
	// Nullable : null ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Nullable : ∙not null
	{
		token.T_14: "not",
	},
	// Nullable : not ∙null
	{
		token.T_15: "null",
	},
	// Nullable : not null ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// PrimaryKey : ∙PK
	{
		token.T_4: "PK",
	},
	// PrimaryKey : PK ∙
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// Schema : ∙schema SchemaName ERM
	{
		token.T_17: "schema",
	},
	// Schema : schema ∙SchemaName ERM
	{
		token.T_13: "name",
	},
	// Schema : schema SchemaName ∙ERM
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// Schema : schema SchemaName ERM ∙
	{
		token.EOF: "$",
	},
	// SchemaName : ∙Name
	{
		token.T_13: "name",
	},
	// SchemaName : Name ∙
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// SequenceNumber : ∙posint
	{
		token.T_16: "posint",
	},
	// SequenceNumber : posint ∙
	{
		token.T_1: ";",
	},
	// TypeName : ∙bin
	{
		token.T_6: "bin",
	},
	// TypeName : bin ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙bool
	{
		token.T_7: "bool",
	},
	// TypeName : bool ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙date
	{
		token.T_8: "date",
	},
	// TypeName : date ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙decimal
	{
		token.T_9: "decimal",
	},
	// TypeName : decimal ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙int
	{
		token.T_11: "int",
	},
	// TypeName : int ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙serial
	{
		token.T_18: "serial",
	},
	// TypeName : serial ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙text
	{
		token.T_20: "text",
	},
	// TypeName : text ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// TypeName : ∙time
	{
		token.T_21: "time",
	},
	// TypeName : time ∙
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Unique : ∙unique
	{
		token.T_22: "unique",
	},
	// Unique : unique ∙
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
}

var followSets = []map[token.Type]string{
	// AttributeDeclaration
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// AttributeDeclarations
	{
		token.T_24: "}",
	},
	// AttributeName
	{
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_11: "int",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
	},
	// Constraint
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Constraints
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// Description
	{
		token.T_2: "=",
	},
	// ERM
	{
		token.EOF: "$",
	},
	// Entity
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// EntityName
	{
		token.T_0:  ".",
		token.T_23: "{",
	},
	// EntityOrEnum
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// Enum
	{
		token.EOF:  "$",
		token.T_10: "enum",
		token.T_13: "name",
	},
	// EnumItem
	{
		token.T_19: "string",
		token.T_24: "}",
	},
	// EnumItemName
	{
		token.T_2:  "=",
		token.T_19: "string",
	},
	// EnumItems
	{
		token.T_24: "}",
	},
	// FieldName
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// ForeignKey
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Name
	{
		token.T_0:  ".",
		token.T_3:  "FK",
		token.T_6:  "bin",
		token.T_7:  "bool",
		token.T_8:  "date",
		token.T_9:  "decimal",
		token.T_10: "enum",
		token.T_11: "int",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_18: "serial",
		token.T_20: "text",
		token.T_21: "time",
		token.T_22: "unique",
		token.T_23: "{",
		token.T_24: "}",
	},
	// Nullable
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// PrimaryKey
	{
		token.T_13: "name",
		token.T_24: "}",
	},
	// Schema
	{
		token.EOF: "$",
	},
	// SchemaName
	{
		token.T_10: "enum",
		token.T_13: "name",
	},
	// SequenceNumber
	{
		token.T_1: ";",
	},
	// TypeName
	{
		token.T_3:  "FK",
		token.T_4:  "PK",
		token.T_5:  "[]",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
	// Unique
	{
		token.T_3:  "FK",
		token.T_13: "name",
		token.T_14: "not",
		token.T_15: "null",
		token.T_22: "unique",
		token.T_24: "}",
	},
}

/*** Errors ***/

/*
Error is returned by Parse at every point at which the parser fails to parse
a grammar production. For non-LL-1 grammars there will be an error for each
alternate attempted by the parser.

The errors are sorted in descending order of input position (index of token in
the stream of tokens).

Normally the error of interest is the one that has parsed the largest number of
tokens.
*/
type Error struct {
	// Index of token that caused the error.
	cI int

	// Grammar slot at which the error occured.
	Slot slot.Label

	// The token at which the error occurred.
	Token *token.Token

	// The line and column in the input text at which the error occurred
	Line, Column int

	// The tokens expected at the point where the error occurred
	Expected map[token.Type]string
}

func (pe *Error) String() string {
	w := new(bytes.Buffer)
	fmt.Fprintf(w, "Parse Error: %s I[%d]=%s at line %d col %d\n",
		pe.Slot, pe.cI, pe.Token, pe.Line, pe.Column)
	exp := []string{}
	for _, e := range pe.Expected {
		exp = append(exp, e)
	}
	fmt.Fprintf(w, "Expected one of: [%s]", strings.Join(exp, ","))
	return w.String()
}

func (p *parser) parseError(slot slot.Label, i int, expected map[token.Type]string) {
	pe := &Error{cI: i, Slot: slot, Token: p.lex.Tokens[i], Expected: expected}
	p.parseErrors = append(p.parseErrors, pe)
}

func (p *parser) sortParseErrors() {
	sort.Slice(p.parseErrors,
		func(i, j int) bool {
			return p.parseErrors[j].Token.Lext() < p.parseErrors[i].Token.Lext()
		})
	for _, pe := range p.parseErrors {
		pe.Line, pe.Column = p.lex.GetLineColumn(pe.Token.Lext())
	}
}
